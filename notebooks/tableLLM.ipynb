{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/gime-extract/miniconda3/envs/llmenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
=======
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import csv\n",
    "import torch\n",
    "import difflib\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    "    GenerationConfig,\n",
    "    TextStreamer,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import re\n",
    "\n",
    "data = pd.read_csv('../data/pseudo_json_dataset_V3_2048.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
<<<<<<< HEAD
=======
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'RUCKBReasoning/TableLLM-13b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'RUCKBReasoning/TableLLM-7b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 4,
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.69s/it]\n"
=======
      "Loading checkpoint shards: 100%|██████████| 6/6 [03:12<00:00, 32.15s/it]\n"
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
<<<<<<< HEAD
      "  \"eos_token_id\": 2\n",
=======
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0\n",
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, device_map=\"auto\", torch_dtype=torch.float16,\n",
    ")\n",
    "generation_config = GenerationConfig.from_pretrained(model_id)\n",
    "print(generation_config)\n",
    "\n",
    "\n",
    "generation_config.max_new_tokens = 512\n",
    "generation_config.temperature = 0.0001\n",
    "generation_config.do_sample = True\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 5,
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=True,\n",
    "    generation_config=generation_config,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    # streamer=streamer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 6,
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(ip):\n",
    "    # Find the index of \"[/INST]\"\n",
    "    index = ip.find(\"[/INST]\")\n",
    "\n",
    "    # Extract the value after \"[/INST]\"\n",
    "    if index != -1:\n",
    "        extracted_value = ip[index + len(\"[/INST]\") + 1:].strip()  # Add 1 to skip the \"]\" character\n",
    "        return extracted_value\n",
    "    else:\n",
    "        print(\"No value found after '[/INST]'\")\n",
    "\n",
    "def extract_second(ip):\n",
    "   # Find the first occurrence of \"[/INST]\"\n",
    "    first_inst_index = ip.find(\"[/INST]\")\n",
    "\n",
    "    # Find the second occurrence of \"[/INST]\" starting from the position after the first one\n",
    "    second_inst_index = ip.find(\"[/INST]\", first_inst_index + len(\"[/INST]\"))\n",
    "\n",
    "    # Extract the value after the second \"[/INST]\"\n",
    "    if second_inst_index != -1:\n",
    "        extracted_value = ip[second_inst_index + len(\"[/INST]\") + 1:].strip()  # Add 1 to skip the \"]\" character\n",
    "        return extracted_value\n",
    "    else:\n",
    "        print(\"Two occurrences of '[/INST]' not found\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 7,
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(columns=['csv', 'question', 'answer', 'prediction'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 21,
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(csv_data, question):\n",
    "    ip = f\"\"\"[INST]Offer a thorough and accurate solution that directly addresses the Question outlined in the [Question]. You have to only give extract the exact answer to the user.\n",
    "\n",
    "    ### [Table]\n",
    "    {csv_data}\n",
    "\n",
    "    ### [Question]\n",
    "    {question}\n",
    "\n",
    "    ### [Solution]\n",
    "    [/INST]\"\"\"\n",
    "    return ip "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoshot_prompt_formatter(csv_data, question):\n",
    "    ip = f\"\"\"[INST]Offer a thorough and accurate solution that directly addresses the Question outlined in the [Question].\n",
    "\n",
    "    ### [Table]\n",
    "    1,-,2002,2001,2000\n",
    "    2,net sales,$ 5742,$ 5363,$ 7983\n",
    "    3,cost of sales,4139,4128,5817\n",
    "    4,gross margin,$ 1603,$ 1235,$ 2166\n",
    "    5,gross margin percentage,28% ( 28 % ),23% ( 23 % ),27% ( 27 % )\n",
    "\n",
    "\n",
    "    ### [Question]\n",
    "    what is the gross margin in 2002?\n",
    "\n",
    "    ### [Solution]\n",
    "    [/INST] $1603.\n",
    "\n",
    "    [INST]Offer a thorough and accurate solution that directly addresses the Question outlined in the [Question].\n",
=======
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter_for_code(csv_data, question):\n",
    "    ip = f\"\"\"[INST]Below are the first few lines of a CSV file. You need to write a Python program to solve the provided question.\n",
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
    "\n",
    "    Header and first few lines of CSV file:\n",
    "    {csv_data}\n",
    "\n",
    "    Question: {question}[/INST]\n",
    "    \"\"\"\n",
    "    return ip "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [02:07, 127.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "193.3\n",
      "The table shows the global payments data for May 31, 2005. The gross margin for that date is $193.30. Therefore, the answer to the question is $193.30.\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [04:15, 127.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "39\n",
      "To find the total for 2010, we need to look at the \"total (in $ millions)\" column in the table. From the given table, we can see that the total for 2010 is $39 million.\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [05:26, 101.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "$ -\n",
      "The credit facilities [a] for amount of commitment expiration per period after 2014 is $1900.\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [07:19, 106.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "3.4% ( 3.4 % )\n",
      "To determine the core price for 2006, we need to refer to the table provided.\n",
      "\n",
      "According to the table, the core price for 2006 is $2.4.\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [08:05, 84.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "['-86 ( 86 )' '$ 56.53' '$ 999343' '$ 926512']\n",
      "The value for canceled in the table is $999343.\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [09:04, 75.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "2.3\n",
      "The weighted average dilutive effect of equity awards for 2018 is 2.3.\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [10:03, 70.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "$311\n",
      "According to the table, the interest and dividend income for 2010 is $311.\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [11:11, 69.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "$24490\n",
      "The cash cash equivalents and marketable securities for 2008 is $24490.\n",
      "***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [14:52, 116.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "$77.15\n",
      "To find the average price paid per share in October 2017, we can refer to the table provided. \n",
      "\n",
      "In the table, the average price paid per share is listed under the \"october 2017\" column. The value in this column is $77.15.\n",
      "\n",
      "Therefore, the average price paid per share in October 2017 is $77.15.\n",
      "***\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest = data.loc[50, 'question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the value for syndicated letter of credit facility ?'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
    }
   ],
   "source": [
    "quest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest1 = \"syndicated letter of credit facility\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['$ 1000' '$ 574' 'nov . 2012' '$ 631179' '$ 693928' '540836']\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[50, 'answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_csv(table):\n",
    "    # Open StringIO object for writing\n",
    "    csv_buffer = StringIO()\n",
    "\n",
    "\n",
    "    # Write rows to the StringIO object\n",
    "    writer = csv.writer(csv_buffer)\n",
    "    trows = table.find_all('tr')\n",
    "    for trow in trows:\n",
    "        writer.writerow([cell.get_text() for cell in trow.find_all(['td', 'th'])])\n",
    "\n",
    "\n",
    "    # Get the CSV data as a string\n",
    "    csv_data = csv_buffer.getvalue()\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_rows(table):\n",
    "    # Open StringIO object for writing\n",
    "    csv_buffer = StringIO()\n",
    "    # Write rows to the StringIO object\n",
    "    writer = csv.writer(csv_buffer)\n",
    "    trows = table.find_all('tr')\n",
    "    for trow in trows:\n",
    "        writer.writerow([cell.get_text() for cell in trow.find_all(['td', 'th'])])\n",
    "\n",
    "\n",
    "    return trows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_rows(data, index):\n",
    "    soup = BeautifulSoup(data.loc[index, 'html_content'], 'html.parser')\n",
    "\n",
    "    # Find the table\n",
    "    table = soup.find('table')\n",
    "    csv_data = save_rows(table)\n",
    "    return csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutput_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone_shot_test_v1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_df' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "output_df.to_csv('one_shot_test_v1.csv', index=False)"
=======
    "def example(data, index):\n",
    "    soup = BeautifulSoup(data.loc[index, 'html_content'], 'html.parser')\n",
    "\n",
    "    # Find the table\n",
    "    table = soup.find('table')\n",
    "    csv_data = save_rows(table)\n",
    "    return csv_data"
>>>>>>> 3b4a9ecaf620eeb47723534df1ed0d5c666bd700
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr>\n",
      "<td>\n",
      "     1\n",
      "    </td>\n",
      "<td>\n",
      "     ( in millions of u.s . dollars )\n",
      "    </td>\n",
      "<td>\n",
      "     creditline ( 1 )\n",
      "    </td>\n",
      "<td>\n",
      "     usage\n",
      "    </td>\n",
      "<td>\n",
      "     expiry date\n",
      "    </td>\n",
      "</tr>, <tr>\n",
      "<td>\n",
      "     2\n",
      "    </td>\n",
      "<td>\n",
      "     syndicated letter of credit facility\n",
      "    </td>\n",
      "<td>\n",
      "     $ 1000\n",
      "    </td>\n",
      "<td>\n",
      "     $ 574\n",
      "    </td>\n",
      "<td>\n",
      "     nov . 2012\n",
      "    </td>\n",
      "</tr>, <tr>\n",
      "<td>\n",
      "     3\n",
      "    </td>\n",
      "<td>\n",
      "     revolving credit/loc facility ( 2 )\n",
      "    </td>\n",
      "<td>\n",
      "     500\n",
      "    </td>\n",
      "<td>\n",
      "     370\n",
      "    </td>\n",
      "<td>\n",
      "     nov . 2012\n",
      "    </td>\n",
      "</tr>, <tr> <td> 2 </td> <td> syndicated letter of credit facility </td> <td> $ 631179 </td> <td> $ 693928 </td> <td> 540836 </td> </tr>, <tr>\n",
      "<td>\n",
      "     4\n",
      "    </td>\n",
      "<td>\n",
      "     bilateral letter of credit facility\n",
      "    </td>\n",
      "<td>\n",
      "     500\n",
      "    </td>\n",
      "<td>\n",
      "     500\n",
      "    </td>\n",
      "<td>\n",
      "     sept . 2014\n",
      "    </td>\n",
      "</tr>, <tr>\n",
      "<td>\n",
      "     5\n",
      "    </td>\n",
      "<td>\n",
      "     funds at lloyds 2019s capital facilities ( 3 )\n",
      "    </td>\n",
      "<td>\n",
      "     400\n",
      "    </td>\n",
      "<td>\n",
      "     340\n",
      "    </td>\n",
      "<td>\n",
      "     dec . 2015\n",
      "    </td>\n",
      "</tr>, <tr>\n",
      "<td>\n",
      "     6\n",
      "    </td>\n",
      "<td>\n",
      "     total\n",
      "    </td>\n",
      "<td>\n",
      "     $ 2400\n",
      "    </td>\n",
      "<td>\n",
      "     $ 1784\n",
      "    </td>\n",
      "<td>\n",
      "     -\n",
      "    </td>\n",
      "</tr>]\n"
     ]
    }
   ],
   "source": [
    "example_csv = example_rows(data, 50)\n",
    "print(example_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr>\n",
       "<td>\n",
       "     1\n",
       "    </td>\n",
       "<td>\n",
       "     ( in millions of u.s . dollars )\n",
       "    </td>\n",
       "<td>\n",
       "     creditline ( 1 )\n",
       "    </td>\n",
       "<td>\n",
       "     usage\n",
       "    </td>\n",
       "<td>\n",
       "     expiry date\n",
       "    </td>\n",
       "</tr>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_csv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr>\n",
       "<td>\n",
       "     2\n",
       "    </td>\n",
       "<td>\n",
       "     syndicated letter of credit facility\n",
       "    </td>\n",
       "<td>\n",
       "     $ 1000\n",
       "    </td>\n",
       "<td>\n",
       "     $ 574\n",
       "    </td>\n",
       "<td>\n",
       "     nov . 2012\n",
       "    </td>\n",
       "</tr>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_csv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_embed = tokenizer.encode(quest)\n",
    "quest_embed1 = tokenizer.encode(quest1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arrays_equal_length(arr1, arr2):\n",
    "    max_length = max(len(arr1), len(arr2))\n",
    "    arr1 += [0] * (max_length - len(arr1))\n",
    "    arr2 += [0] * (max_length - len(arr2))\n",
    "    return np.array(arr1), np.array(arr2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.44096208e-01 -4.47803557e-01  4.59621623e-02 -4.41596359e-02\n",
      "  4.11756545e-01 -3.08305800e-01  1.30668044e-01 -3.73839676e-01\n",
      " -4.38299298e-01  3.49975377e-01 -4.50063407e-01  6.28146708e-01\n",
      "  8.73845816e-02  4.61639702e-01 -4.87383418e-02 -2.85761386e-01\n",
      " -1.08402215e-01 -4.04760033e-01  7.23943710e-01  3.29313241e-02\n",
      " -5.86703300e-01  7.76682734e-01  1.03727289e-01  1.98982537e-01\n",
      "  1.32318046e-02  1.01303148e+00  7.45108247e-01 -2.55685896e-01\n",
      " -1.30008614e+00 -5.79248241e-04  2.75156558e-01 -1.06333303e+00\n",
      "  4.99370366e-01  1.69249386e-01  7.30321586e-01 -3.54087889e-01\n",
      "  4.09221292e-01 -4.45096284e-01 -4.51519847e-01 -1.39599550e+00\n",
      "  2.33045802e-01 -1.17108986e-01  4.73732620e-01  5.54763794e-01\n",
      " -3.97603154e-01 -6.32116377e-01 -1.47040367e+00  5.30318618e-01\n",
      " -9.20125067e-01 -1.34734184e-01  7.07672358e-01  3.86733174e-01\n",
      "  1.58505663e-02  7.92560458e-01  6.82924688e-01  1.09888923e+00\n",
      " -1.06049553e-01 -1.36935568e+00  2.19154745e-01 -5.95036268e-01\n",
      "  2.37876952e-01 -9.47821975e-01  5.70348680e-01  1.03095126e+00\n",
      " -5.65587163e-01 -4.67570901e-01 -1.70373991e-01 -1.12209424e-01\n",
      " -5.86601913e-01 -7.50103593e-01  1.00518215e+00 -6.26699552e-02\n",
      " -5.50690949e-01 -2.05781832e-01 -8.63139093e-01 -3.23979706e-01\n",
      " -7.43940115e-01  6.74456835e-01 -1.94736078e-01 -3.13462466e-01\n",
      " -1.18638492e+00  4.76993263e-01 -1.52102867e-02  6.04412407e-02\n",
      " -5.01012444e-01  1.22539289e-01 -2.42177560e-03  1.50791064e-01\n",
      " -2.44733896e-02  5.50910830e-01 -1.95798382e-01  4.39077973e-01\n",
      " -7.45347857e-01 -5.36231041e-01  5.10650039e-01 -9.84593034e-01\n",
      " -4.90224659e-01  3.67833585e-01 -3.39634538e-01 -2.53581703e-01\n",
      " -7.24401176e-01 -5.01021087e-01  3.63024503e-01 -3.12850803e-01\n",
      "  1.78207099e-01 -1.89642251e-01 -4.04287189e-01 -4.45459366e-01\n",
      " -7.40065426e-02  6.81414187e-01 -4.99525666e-01 -6.86885715e-01\n",
      "  8.89172494e-01  8.05410221e-02  2.10318878e-01 -4.74366248e-01\n",
      " -3.70663643e-01 -1.54979840e-01 -6.95807755e-01  1.13963199e+00\n",
      " -3.79090250e-01 -3.75766456e-01 -1.56877339e-01 -1.20686102e+00\n",
      "  1.00916791e+00 -3.79847169e-01 -5.19400775e-01 -4.30996835e-01\n",
      " -3.26369733e-01  2.34979093e-01  8.73845339e-01  3.39244306e-01\n",
      " -1.37133792e-01  2.12387562e-01 -1.82371244e-01 -3.56184751e-01\n",
      " -7.61789739e-01 -4.14428115e-01 -5.72933614e-01 -1.02397394e+00\n",
      " -5.36564291e-01  9.11405832e-02 -4.47935760e-01 -5.47906458e-01\n",
      " -3.96473885e-01 -4.78842556e-01 -2.69970357e-01  5.04346848e-01\n",
      " -2.60269940e-01 -2.56292880e-01  4.07744616e-01 -2.48794496e-01\n",
      " -3.11280280e-01 -1.61212593e-01  1.11070049e+00 -8.11075509e-01\n",
      "  2.20329449e-01  5.99115729e-01 -5.42585552e-01  1.73942819e-01\n",
      "  5.75169176e-02  8.63103569e-01  4.43693489e-01 -5.69498241e-01\n",
      " -3.38605613e-01  2.94193625e-01  1.02684784e+00  2.73767747e-02\n",
      " -7.67181039e-01  3.97802681e-01 -9.11467195e-01 -4.04693067e-01\n",
      "  2.90694088e-01 -1.82686269e-01  4.57013935e-01  3.99869412e-01\n",
      "  4.35408086e-01  6.37745500e-01  2.96031028e-01  4.25107509e-01\n",
      "  8.71046931e-02  9.06938851e-01 -7.88218379e-01  7.62690902e-01\n",
      "  2.89385200e-01  3.62028539e-01 -5.72361201e-02  8.33498418e-01\n",
      "  5.51492631e-01  5.06922841e-01 -5.67689180e-01 -5.58464289e-01\n",
      " -5.76538801e-01 -6.22060120e-01 -2.42782921e-01  1.63947552e-01\n",
      " -7.52923131e-01  5.07061005e-01  1.95610046e-01  3.21652472e-01\n",
      " -5.36754765e-02  1.49533808e-01  1.01214743e+00 -9.83663499e-01\n",
      " -3.21480110e-02  5.21129370e-02  6.13375455e-02  5.97016335e-01\n",
      "  2.97140986e-01 -5.82391143e-01  7.21256137e-01 -4.70156372e-01\n",
      " -3.93044263e-01  3.35099816e-01 -3.94279987e-01 -1.32727027e+00\n",
      "  6.02952600e-01  5.02187237e-02  3.96581322e-01  9.07188356e-02\n",
      "  8.02035034e-01 -9.23450172e-01  2.32018918e-01  5.58580458e-01\n",
      " -3.28762680e-01  2.05176428e-01 -1.21480279e-01 -1.37218852e-02\n",
      "  9.41226423e-01  9.33195531e-01  2.99791425e-01 -5.14419615e-01\n",
      " -3.99716169e-01 -3.97673965e-01 -3.45070183e-01 -1.38303041e-02\n",
      " -3.10279697e-01  4.05240685e-01 -1.37029827e-01  1.01314044e+00\n",
      " -6.54598922e-02  4.18945819e-01 -3.41865003e-01 -5.67795157e-01\n",
      " -4.75549370e-01 -2.18353570e-01  1.25856221e-01  1.34075508e-01\n",
      "  2.30142564e-01 -2.17691630e-01  2.05805317e-01  2.38543913e-01\n",
      "  1.75062984e-01 -1.67482361e-01  5.87780118e-01  5.81071138e-01\n",
      " -3.27068359e-01  9.25816774e-01  1.91158533e-01 -8.39418411e-01\n",
      "  1.69411108e-01  2.64762551e-01 -9.43524301e-01 -4.51365471e-01\n",
      "  1.24635971e+00  6.08582616e-01  4.70974028e-01  1.80604458e-01\n",
      " -2.26388305e-01 -1.16525739e-01  2.37344690e-02  2.60520756e-01\n",
      " -1.80838078e-01 -4.38173443e-01 -3.17284226e-01 -5.92546999e-01\n",
      "  1.85581779e+00 -7.36849681e-02 -3.44669700e-01 -1.02414146e-01\n",
      " -5.15713573e-01  4.50768530e-01 -3.35876606e-02 -8.18495333e-01\n",
      "  4.20375407e-01  2.20359745e-03  4.86918241e-01  2.84196794e-01\n",
      " -4.16964859e-01  1.80675179e-01 -3.57174039e-01 -2.11153731e-01\n",
      " -5.27502954e-01 -3.17355752e-01 -5.48904955e-01  4.95048791e-01\n",
      "  2.91991204e-01 -2.89453901e-02 -3.62429738e-01 -6.84143484e-01\n",
      "  1.06256381e-01 -2.85688400e-01  2.07295809e-02  7.91482866e-01\n",
      "  3.11988860e-01 -6.24419153e-01 -1.33521330e+00  1.27057517e+00\n",
      " -1.07862496e+00  2.86749601e-01 -8.94382596e-01 -4.54684705e-01\n",
      "  9.02186990e-01 -7.33248472e-01 -5.24901509e-01  5.14172137e-01\n",
      "  3.88569474e-01 -9.93963838e-01 -6.18311465e-01 -6.51205957e-01\n",
      "  5.05238950e-01 -4.16046113e-01 -3.29777598e-01 -7.76576325e-02\n",
      " -1.89542234e-01  3.96740705e-01  1.62894413e-01  6.64529055e-02\n",
      "  1.14453614e+00 -1.07880831e+00  1.21270168e+00  7.33590961e-01\n",
      " -8.36083114e-01  5.84501982e-01 -3.12415481e-01  3.36828917e-01\n",
      "  5.60934603e-01 -3.59666310e-02  4.42482352e-01  1.34731770e-01\n",
      "  1.01481867e+00  1.22076917e+00  4.35092926e-01 -2.90574074e-01\n",
      "  2.27421373e-01  2.61643887e-01  1.04512894e+00  1.05318785e-01\n",
      "  1.02194035e+00 -8.70947391e-02  5.59609354e-01  2.21948043e-01\n",
      " -7.73914680e-02  1.43012017e-01 -7.23048210e-01  3.32353443e-01\n",
      " -9.44108218e-02  2.93562770e-01  3.44540417e-01  8.81550789e-01\n",
      " -1.37657315e-01  9.11821604e-01 -4.72372025e-01 -1.01972282e+00\n",
      " -1.15214936e-01 -4.37428474e-01 -4.01521176e-02  5.97384155e-01\n",
      "  4.42462862e-01 -3.39525670e-01  5.44006884e-01 -9.16159570e-01\n",
      " -7.39348769e-01  1.75359398e-01 -1.01017106e+00  6.02633893e-01\n",
      "  4.09213513e-01  6.25386894e-01 -5.05338646e-02 -8.40701312e-02\n",
      " -4.92895573e-01 -6.50370896e-01 -3.67402971e-01 -3.49025458e-01\n",
      "  1.09865510e+00  4.70523179e-01  4.75813240e-01  6.46334887e-02\n",
      "  3.31545323e-01 -2.31727853e-01  6.12147391e-01 -5.54469645e-01\n",
      "  7.39428639e-01 -5.87921143e-01 -1.35064095e-01 -8.72603834e-01\n",
      " -7.76399672e-02 -3.23842794e-01 -3.88820201e-01 -1.23947525e+00\n",
      " -3.93461019e-01 -7.36332655e-01 -5.46160862e-02 -1.33632159e+00\n",
      " -4.61667567e-01  9.24051628e-02  9.45713148e-02 -7.32283518e-02\n",
      "  3.88297230e-01  2.14988571e-02  3.42628330e-01 -1.15208578e+00\n",
      " -4.75860238e-01 -5.80656886e-01 -8.15172553e-01  1.75938353e-01\n",
      " -8.96017924e-02  7.65514493e-01 -3.37726057e-01  4.17105973e-01\n",
      "  1.10717001e-03 -1.01525128e+00 -6.71414584e-02  4.40890014e-01\n",
      " -5.23655057e-01 -2.14873571e-02  2.26109058e-01  2.70721942e-01\n",
      "  1.12808716e+00 -1.04087159e-01  4.37013596e-01 -2.20427305e-01\n",
      " -3.95115882e-01  1.05617154e+00 -3.32314014e-01  8.92856121e-02\n",
      " -7.01841339e-02  3.44416797e-01  5.71718514e-01 -9.91369843e-01\n",
      " -5.40113389e-01 -6.12019226e-02 -4.24915671e-01  1.43623912e+00\n",
      " -7.32483208e-01  2.27421135e-01  1.75773308e-01 -9.25300539e-01\n",
      "  1.73868835e-01  7.43566453e-02 -1.64869010e-01  4.64251518e-01\n",
      " -1.83431014e-01 -2.87328362e-01 -4.85654205e-01  4.07779813e-02\n",
      "  5.95872343e-01 -5.73654890e-01  1.33886412e-01 -6.59039736e-01\n",
      " -9.56760466e-01 -2.21275866e-01  4.57112379e-02 -3.11358511e-01\n",
      " -2.45603889e-01  1.76578209e-01 -8.77270937e-01  8.98825284e-03\n",
      "  1.24597877e-01  3.01919207e-02 -1.24302991e-01  6.77925348e-01\n",
      " -6.80676699e-01 -1.65067449e-01  1.89347848e-01 -6.69292331e-01\n",
      "  3.19867641e-01  2.93927789e-01 -2.15597123e-01 -1.62077039e-01\n",
      "  6.01483941e-01  7.26194441e-01  8.04425597e-01  9.61247981e-01\n",
      "  3.89142632e-01 -3.23031843e-01  9.74112451e-01  5.15902519e-01\n",
      "  3.23761016e-01  1.02428392e-01  1.80039585e-01  5.95000803e-01\n",
      "  4.42678899e-01  6.88460395e-02 -1.02682658e-01  4.97583598e-01\n",
      " -1.17701316e+00 -2.41808087e-01  1.36357379e+00  5.82971334e-01\n",
      "  6.18289948e-01  3.53503555e-01 -1.05973506e+00  3.63790005e-01\n",
      "  6.70548454e-02  1.18167865e+00 -2.89007246e-01  1.19701862e+00\n",
      " -9.60111082e-01  3.27384144e-01  2.22200245e-01  6.54203147e-02\n",
      " -4.81128335e-01  3.68538409e-01  6.19443297e-01  2.47381851e-01\n",
      "  2.58237541e-01  9.70878482e-01  3.19986403e-01 -2.00131789e-01\n",
      " -5.85872866e-02  3.32412034e-01 -6.23396225e-02 -3.50149959e-01\n",
      " -1.96876302e-01 -8.93262122e-03  4.47628528e-01 -1.85332596e-01\n",
      "  1.00699651e+00  6.42594770e-02  4.40643758e-01  2.25749940e-01\n",
      "  1.05126627e-01  3.41750085e-01 -3.47029895e-01 -5.86619318e-01\n",
      " -2.56792665e-01  9.65216696e-01  7.16407418e-01 -1.08597648e+00\n",
      "  6.04222536e-01 -2.28251427e-01  4.58575368e-01  3.34477276e-02\n",
      "  9.28311422e-02 -3.06725264e-01 -1.03071404e+00 -8.12093318e-01\n",
      " -1.75387412e-01 -6.12519264e-01 -8.58761743e-03 -6.83970153e-01\n",
      " -1.51463196e-01  8.25580180e-01  6.08722687e-01 -8.45962763e-02\n",
      " -3.33238959e-01  5.71673810e-01  1.63118225e-02  6.34177804e-01\n",
      " -2.37531573e-01  2.37691566e-01  1.20984718e-01  4.70754296e-01\n",
      " -3.59836876e-01 -1.29321724e-01 -2.14729860e-01  6.38888955e-01\n",
      "  1.08968824e-01  9.49518085e-01 -3.40165384e-02  1.17699102e-01\n",
      " -1.33009488e-02 -7.30384469e-01  3.18444908e-01 -3.19552422e-01\n",
      "  7.91156769e-01  4.49036285e-02  4.84129608e-01 -8.46108139e-01\n",
      " -5.32158971e-01  6.42723739e-01  8.72644544e-01 -5.18011227e-02\n",
      "  8.83490026e-01 -5.44872701e-01  2.76256144e-01  1.95748359e-01\n",
      " -2.49519274e-01 -8.38722169e-01 -2.36737113e-02 -2.62176633e-01\n",
      " -6.27959788e-01 -3.06007087e-01  2.10897774e-01  7.77963340e-01\n",
      " -1.33789480e-01  5.91599464e-01 -6.41633093e-01 -4.64108109e-01\n",
      " -5.10931253e-01 -2.47303039e-01 -7.33306170e-01  9.96182382e-01\n",
      " -2.47868240e-01 -6.37082636e-01 -5.61467558e-02 -5.99669665e-02\n",
      " -9.02597904e-02  1.19243729e+00  8.43373954e-01 -6.05492592e-01\n",
      " -2.58613646e-01 -1.85525626e-01 -8.22758794e-01 -2.70981044e-01\n",
      " -3.46868664e-01  4.43382077e-02 -2.71873176e-01 -7.24721670e-01\n",
      " -2.17602596e-01  1.37517124e-01  6.57977834e-02  7.26410300e-02\n",
      " -6.09837770e-01  1.59566700e-01 -7.00129390e-01 -4.39983189e-01\n",
      "  4.06628639e-01 -5.49709082e-01  3.09123486e-01  1.02436796e-01\n",
      " -4.76150811e-01  4.79061574e-01 -1.74676999e-01 -6.69598281e-01\n",
      " -2.53555924e-01  2.25397479e-02  4.16771531e-01 -5.71953595e-01\n",
      " -3.84444445e-02 -5.49921393e-01 -2.25745827e-01 -3.53387062e-04\n",
      " -6.74507439e-01 -1.93554070e-02 -4.91340488e-01  5.76215982e-01\n",
      " -4.15576160e-01 -2.27611512e-01  1.65988028e-01  5.33416510e-01\n",
      " -3.55858147e-01  7.55722880e-01  1.02818298e+00  4.24982280e-01\n",
      "  1.26662135e+00 -2.35551283e-01  8.42760384e-01  3.85567732e-02\n",
      "  1.01608145e+00  7.84863591e-01  5.26093602e-01 -1.09774441e-01\n",
      "  6.83806777e-01 -1.39740512e-01  9.40696448e-02 -9.20050085e-01\n",
      " -2.62239665e-01  5.11553049e-01  1.04219370e-01 -9.16302025e-01\n",
      "  9.64990407e-02 -9.36009765e-01 -7.75743365e-01 -4.10972565e-01\n",
      "  1.06175661e+00  9.03463900e-01 -4.95132655e-01  1.37063235e-01\n",
      "  4.42071706e-01  7.49796182e-02  3.41458052e-01 -2.70772781e-02\n",
      " -4.40570712e-01  8.05330276e-01 -6.35460317e-01  2.30705589e-01\n",
      " -3.18697989e-01 -8.45512688e-01  3.78228694e-01 -6.39371753e-01\n",
      "  1.44609436e-01 -3.72998059e-01  2.89156973e-01 -9.74072397e-01\n",
      " -2.02493086e-01 -6.72781050e-01  1.48897901e-01 -1.59879279e+00\n",
      " -1.21074367e+00  3.75926375e-01  7.84080744e-01  1.77301317e-01\n",
      " -7.42797256e-01 -5.43242514e-01  7.05058932e-01  9.59211290e-02\n",
      " -3.91048431e-01 -6.91617250e-01  4.77755100e-01 -4.76701796e-01\n",
      " -5.85258782e-01  3.13827507e-02  1.81454849e+00  4.08326745e-01\n",
      " -3.41005325e-01 -1.39786467e-01  3.82604152e-01 -1.10931945e+00\n",
      " -1.65507644e-02  1.84505716e-01 -5.26449144e-01  2.57131875e-01\n",
      " -4.51846153e-01 -8.14108551e-01  2.27493152e-01 -2.70353049e-01\n",
      " -1.50587901e-01 -1.60561293e-01 -6.68788195e-01 -4.83300894e-01\n",
      " -4.12272304e-01  5.57876348e-01 -3.62173140e-01  3.48190278e-01\n",
      " -1.14828825e+00  2.19142437e-01  3.58571172e-01 -4.17640209e-02\n",
      "  1.37419701e-01  1.08545095e-01  8.85290205e-02 -2.40751266e-01\n",
      "  5.64376265e-02  1.43075913e-01 -7.36265123e-01 -1.92546859e-01\n",
      "  2.69813836e-01  2.01817885e-01  1.17981527e-02 -2.66809642e-01\n",
      "  4.85510454e-02  5.93477413e-02  4.17697698e-01 -3.78239274e-01\n",
      " -1.28199264e-01  3.65139365e-01 -1.17913328e-01 -8.41003537e-01\n",
      "  7.32276022e-01 -3.77012193e-01  4.25692722e-02  4.67780530e-01\n",
      " -7.60799348e-01 -4.83913422e-01 -2.20189884e-01  1.15381889e-01]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/bert-base-nli-stsb-mean-tokens')\n",
    "embeddings = model.encode(quest)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_csv1(example_csv):\n",
    "    head = ''\n",
    "    for header in example_csv[0].find_all('td'):\n",
    "        head += header.get_text().replace('\\n', '') + ','\n",
    "\n",
    "    sim = [] \n",
    "    for row in example_csv[1:]:\n",
    "        text1 = str(example_csv[0])+str(row)\n",
    "        text_embed = tokenizer.encode(text1)\n",
    "        array1, array2 = make_arrays_equal_length(text_embed, quest_embed)\n",
    "        array1 = array1.reshape(1, -1)\n",
    "        array2 = array2.reshape(1, -1)\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity(array1, array2)[0][0]\n",
    "        sim.append(similarity)\n",
    "\n",
    "    top_3_max_values = heapq.nlargest(3, sim)\n",
    "    indices = [i for i, value in enumerate(sim) if value in top_3_max_values]\n",
    "\n",
    "    final_csv = \"\"\n",
    "    for index in indices:\n",
    "        value = example_csv[index+1].find_all('td')\n",
    "        for v in value:\n",
    "            final_csv += v.get_text().replace('\\n', '') + ','\n",
    "        final_csv += '\\n'\n",
    "    return head + '\\n' + final_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_csv(example_csv):\n",
    "    head = ''\n",
    "    for header in example_csv[0].find_all('td'):\n",
    "        head += header.get_text().replace('\\n', '') + ','\n",
    "\n",
    "    sim = [] \n",
    "    for row in example_csv[1:]:\n",
    "        text1 = str(example_csv[0])+str(row)\n",
    "        text_embed = tokenizer.encode(text1)\n",
    "        array1, array2 = make_arrays_equal_length(text_embed, quest_embed)\n",
    "        array1 = array1.reshape(1, -1)\n",
    "        array2 = array2.reshape(1, -1)\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity(array1, array2)[0][0]\n",
    "        sim.append(similarity)\n",
    "\n",
    "    top_3_max_values = heapq.nlargest(3, sim)\n",
    "    indices = [i for i, value in enumerate(sim) if value in top_3_max_values]\n",
    "    final_csv = \"\"\n",
    "    for index in indices:\n",
    "        value = example_csv[index+1].find_all('td')\n",
    "        for v in value:\n",
    "            final_csv += v.get_text().replace('\\n', '') + ','\n",
    "        final_csv += '\\n'\n",
    "    return head + '\\n' + final_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(columns=['index', 'question', 'answer', 'prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "0it [00:29, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "     1    ,     -    ,     2016    ,     2015    ,     2014    ,\n",
      "     2    ,     expected term ( in years ) ( 1 )    ,     4.35    ,     4.55    ,     4.80    ,\n",
      "     5    ,     expected dividend yield ( 4 )    ,     0.7% ( 0.7 % )    ,     0.8% ( 0.8 % )    ,     0.8% ( 0.8 % )    ,\n",
      "     6    ,     fair value per option granted    ,     $ 15.01    ,     $ 12.04    ,     $ 11.03    ,\n",
      "\n",
      "questions What is risk-free rate of return ( 2 ) for 2015 ?\n",
      "ground truth 1.5% ( 1.5 % )\n",
      "print(answer)\n",
      "predictions ['import pandas as pd', '', '# Load the CSV file into a DataFrame', \"df = pd.read_csv('data.csv')\", '', \"# Filter the DataFrame to get the row where 'risk-free rate of return ( 2 )' is '2015'\", \"risk_free_rate = df[df['-'] == 'risk-free rate of return ( 2 )'][df['2015'] == '2015']\", '', '# Save the answer in a variable', \"answer = risk_free_rate['-'].values[0]\", '', '# Print the variable', 'print(answer)']\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# with open(filename, 'w') as file:\n",
    "for i, row in tqdm(data[:15].iterrows()):\n",
    "    try: \n",
    "        soup = BeautifulSoup(row['html_content'], 'html.parser')\n",
    "\n",
    "        # Find the table\n",
    "        table = soup.find('table')\n",
    "        csv_data = save_rows(table)\n",
    "        csv_data = get_final_csv(csv_data)\n",
    "        ip = prompt_formatter_for_code(csv_data, row['question'])\n",
    "\n",
    "        output = llm(ip)[0]['generated_text']\n",
    "        print(i)\n",
    "        print(csv_data)\n",
    "        print('questions', row['question'])\n",
    "        print('ground truth', row['answer'])\n",
    "\n",
    "        pred = extract(output) \n",
    "        pred = pred.split('\\n')\n",
    "        ipred = pred[:-1]\n",
    "        final_answer = pred[-1]\n",
    "        print(final_answer)\n",
    "        final_answer = final_answer.replace('print(', 'return ').replace(')', '')\n",
    "        ipred = \n",
    "        print('predictions', pred)\n",
    "        \n",
    "        print('***************************************')\n",
    "        break\n",
    "    except:\n",
    "        print('length of csv is less than 3')\n",
    "    # output_df.at[i, 'csv'] = csv_data\n",
    "    # output_df.at[i, 'question'] = data.loc[i,'question']\n",
    "    # output_df.at[i, 'answer'] = data.loc[i,'answer']\n",
    "    # output_df.at[i, 'prediction'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "1it [00:28, 28.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "     1    ,     -    ,     2016    ,     2015    ,     2014    ,\n",
      "     2    ,     expected term ( in years ) ( 1 )    ,     4.35    ,     4.55    ,     4.80    ,\n",
      "     5    ,     expected dividend yield ( 4 )    ,     0.7% ( 0.7 % )    ,     0.8% ( 0.8 % )    ,     0.8% ( 0.8 % )    ,\n",
      "     6    ,     fair value per option granted    ,     $ 15.01    ,     $ 12.04    ,     $ 11.03    ,\n",
      "\n",
      "questions What is risk-free rate of return ( 2 ) for 2015 ?\n",
      "ground truth 1.5% ( 1.5 % )\n",
      "predictions import pandas as pd\n",
      "\n",
      "# Load the CSV file into a DataFrame\n",
      "df = pd.read_csv('data.csv')\n",
      "\n",
      "# Filter the DataFrame to get the row where 'risk-free rate of return ( 2 )' is '2015'\n",
      "risk_free_rate = df[df['-'] == 'risk-free rate of return ( 2 )'][df['2015'] == '2015']\n",
      "\n",
      "# Save the answer in a variable\n",
      "answer = risk_free_rate['-'].values[0]\n",
      "\n",
      "# Print the variable\n",
      "print(answer)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "2it [00:55, 27.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "     1    ,     in millions    ,     as of december 2012 fair value of investments    ,     as of december 2012 unfunded commitments    ,     as of december 2012 fair value of investments    ,     unfunded commitments    ,\n",
      "     3    ,     credit funds2    ,     3927    ,     2843    ,     3596    ,     3568    ,\n",
      "     4    ,     hedge funds3    ,     2167    ,     2014    ,     3165    ,     2014    ,\n",
      "     5    ,     real estatefunds4    ,     2006    ,     870    ,     1531    ,     1613    ,\n",
      "\n",
      "questions What is credit funds2 for unfunded commitments ?\n",
      "ground truth 3568\n",
      "predictions import pandas as pd\n",
      "\n",
      "     # Read the CSV file\n",
      "     df = pd.read_csv('data.csv')\n",
      "\n",
      "     # Filter the dataframe to get only the row where the 'in millions' column is 'credit funds2'\n",
      "     credit_funds2 = df[df['in millions'] == 'credit funds2']\n",
      "\n",
      "     # Get the 'unfunded commitments' value for credit funds2\n",
      "     unfunded_commitments = credit_funds2['unfunded commitments'].values[0]\n",
      "\n",
      "     # Print the answer\n",
      "     print(unfunded_commitments)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "3it [01:18, 25.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "     1    ,     -    ,     2006    ,\n",
      "     2    ,     net revenue    ,     $ 524340    ,\n",
      "     3    ,     net income    ,     28649    ,\n",
      "     4    ,     net income per share 2014basic    ,     $ 0.55    ,\n",
      "\n",
      "questions What is net income for 2006 ?\n",
      "ground truth 28649\n",
      "predictions import pandas as pd\n",
      "\n",
      "     # Load the CSV file into a DataFrame\n",
      "     df = pd.read_csv('data.csv')\n",
      "\n",
      "     # Filter the DataFrame to only include rows where the 'year' column is 2006\n",
      "     net_income_2006 = df[df['year'] == 2006]['net income'].values[0]\n",
      "\n",
      "     # Print the net income for 2006\n",
      "     print(net_income_2006)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "4it [01:44, 25.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "     1    ,     ( $ in millions )    ,     payments due by period ( a ) total    ,     payments due by period ( a ) less than1 year    ,     payments due by period ( a ) 1-3 years    ,     payments due by period ( a ) 3-5 years    ,     payments due by period ( a ) more than 5 years    ,\n",
      "     3    ,     capital lease obligations    ,     7.6    ,     2.7    ,     2.4    ,     0.4    ,     2.1    ,\n",
      "     4    ,     interest payments on long-term debt ( b )    ,     826.5    ,     138.8    ,     259.4    ,     204.8    ,     223.5    ,\n",
      "     5    ,     operating leases    ,     185.9    ,     45.0    ,     58.5    ,     38.7    ,     43.7    ,\n",
      "\n",
      "questions What is purchase obligations ( c ) for payments due by period ( a ) total ?\n",
      "ground truth 7450.4\n",
      "predictions import pandas as pd\n",
      "\n",
      "# Read the csv file\n",
      "df = pd.read_csv('data.csv')\n",
      "\n",
      "# Get the index of the row where 'payments due by period ( a ) total' is located\n",
      "index = df.columns.get_loc('payments due by period ( a ) total')\n",
      "\n",
      "# Get the value of 'purchase obligations ( c )' for the found index\n",
      "purchase_obligations = df.iloc[:, index].values[0]\n",
      "\n",
      "# Print the result\n",
      "print(purchase_obligations)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "5it [02:09, 25.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "     1    ,     -    ,     2006    ,     2005    ,     2004    ,\n",
      "     2    ,     discretionary matching contributions during the year ended december 31,    ,     $ 3341    ,     $ 2894    ,     $ 2492    ,\n",
      "     3    ,     shares issued during the year ended december 31,    ,     91    ,     215    ,     239    ,\n",
      "     4    ,     shares issuable as of the year ended december 31,    ,     28    ,     19    ,     57    ,\n",
      "\n",
      "questions What is discretionary matching contributions during the year ended december 31, for 2004 ?\n",
      "ground truth $2492\n",
      "predictions import pandas as pd\n",
      "\n",
      "     # Load the csv file into a pandas DataFrame\n",
      "     df = pd.read_csv('data.csv')\n",
      "\n",
      "     # Filter the DataFrame to get the row where the year is 2004\n",
      "filtered_df = df[df['-'] == 'discretionary matching contributions during the year ended december 31']\n",
      "\n",
      "# Get the value for 2004 from the filtered DataFrame\n",
      "answer = filtered_df['2004'].values[0]\n",
      "\n",
      "# Print the answer\n",
      "print(answer)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "6it [02:33, 24.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "     1    ,     -    ,     benefit payments    ,     expected subsidy receipts    ,     net benefit payments    ,\n",
      "     3    ,     2010    ,     3139    ,     91    ,     3048    ,\n",
      "     4    ,     2011    ,     3561    ,     115    ,     3446    ,\n",
      "     5    ,     2012    ,     3994    ,     140    ,     3854    ,\n",
      "\n",
      "questions What is 2010 for benefit payments ?\n",
      "ground truth 3139\n",
      "predictions import pandas as pd\n",
      "\n",
      "# Load the csv file into a pandas DataFrame\n",
      "df = pd.read_csv('data.csv')\n",
      "\n",
      "# Use the 'loc' function to get the value of '2010' for benefit payments\n",
      "benefit_payments_2010 = df.loc[df['-'] == '2010', 'benefit payments'].values[0]\n",
      "\n",
      "# Print the answer\n",
      "print(benefit_payments_2010)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "7it [02:55, 23.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "     1    ,     year ended    ,     operating premises leases    ,\n",
      "     4    ,     2016    ,     621    ,\n",
      "     6    ,     2018    ,     481    ,\n",
      "     7    ,     thereafter    ,     2712    ,\n",
      "\n",
      "questions What is 2018 for operating premises leases ?\n",
      "ground truth 481\n",
      "predictions import pandas as pd\n",
      "\n",
      "     # Read the csv file\n",
      "     df = pd.read_csv('data.csv')\n",
      "\n",
      "     # Filter the dataframe to get the row where year ended is 2018\n",
      "     operating_premises_leases = df[df['year ended'] == '2018']['operating premises leases'].values[0]\n",
      "\n",
      "     # Print the result\n",
      "     print(operating_premises_leases)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "8it [03:15, 22.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "     1    ,     total cumulative return    ,     2010    ,     2011    ,     2012    ,     2013    ,     2014    ,\n",
      "     2    ,     edwards lifesciences    ,     $ 186.16    ,     $ 162.81    ,     $ 207.65    ,     $ 151.43    ,     $ 293.33    ,\n",
      "     3    ,     s&p 500    ,     115.06    ,     117.49    ,     136.30    ,     180.44    ,     205.14    ,\n",
      "     4    ,     s&p 500 healthcare equipment index    ,     96.84    ,     102.07    ,     120.66    ,     153.85    ,     194.33    ,\n",
      "\n",
      "questions What is edwards lifesciences for 2010 ?\n",
      "ground truth $186.16\n",
      "predictions import pandas as pd\n",
      "\n",
      "     # Read the csv file\n",
      "     df = pd.read_csv('data.csv')\n",
      "\n",
      "     # Use loc function to get the value of 'edwards lifesciences' in 2010\n",
      "     value = df.loc[df['total cumulative return'] == 'edwards lifesciences', '2010'].values[0]\n",
      "\n",
      "     # Print the value\n",
      "     print(value)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "9it [03:41, 23.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "     1    ,     ( in millions )    ,     years ended december 31 , 2013    ,     years ended december 31 , 2012    ,     years ended december 31 , 2011    ,\n",
      "     2    ,     weighted-average shares - basic    ,     156.6    ,     145.1    ,     144.8    ,\n",
      "     3    ,     effect of dilutive securities    ,     2.1    ,     0.7    ,     0.1    ,\n",
      "     4    ,     weighted-average shares - diluted    ,     158.7    ,     145.8    ,     144.9    ,\n",
      "\n",
      "questions What is weighted-average shares - basic for years ended december 31 , 2012 ?\n",
      "ground truth 145.1\n",
      "predictions import pandas as pd\n",
      "\n",
      "# Load the data from the CSV file\n",
      "df = pd.read_csv('data.csv')\n",
      "\n",
      "# Get the row where the column name is 'years ended december 31, 2012'\n",
      "row = df[df['years ended december 31, 2012'] == 'weighted-average shares - basic']\n",
      "\n",
      "# Get the value from the row\n",
      "value = row['     ( in millions )     '].values[0]\n",
      "\n",
      "# Print the value\n",
      "print(value)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "10it [04:06, 24.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "     1    ,     in millions    ,     total    ,\n",
      "     3    ,     payments    ,     -78 ( 78 )    ,\n",
      "     5    ,     additional provision    ,     82    ,\n",
      "     8    ,     payments    ,     -38 ( 38 )    ,\n",
      "\n",
      "questions What is balance december 31 2007 for total ?\n",
      "ground truth 46\n",
      "predictions import pandas as pd\n",
      "\n",
      "# Read the CSV file\n",
      "df = pd.read_csv('data.csv')\n",
      "\n",
      "# Filter the dataframe to get the row where the 'total' column is 'December 31, 2007'\n",
      "total_df = df[df['total'] == 'December 31, 2007']\n",
      "\n",
      "# Get the value in the 'total' column for that row\n",
      "total_value = total_df['total'].values[0]\n",
      "\n",
      "# Print the total value\n",
      "print(total_value)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "11it [04:11, 18.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of csv is less than 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "12it [04:38, 20.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "     1    ,     -    ,     total ( in $ millions )    ,\n",
      "     4    ,     2009    ,     50    ,\n",
      "     5    ,     2010    ,     39    ,\n",
      "     8    ,     total    ,     3498    ,\n",
      "\n",
      "questions What is 2010 for total ( in $ millions ) ?\n",
      "ground truth 39\n",
      "predictions import pandas as pd\n",
      "\n",
      "# Load the CSV file into a DataFrame\n",
      "df = pd.read_csv('data.csv')\n",
      "\n",
      "# Filter the DataFrame to only include rows where the 'total ( in $ millions )' column is equal to '2010'\n",
      "df_2010 = df[df['total ( in $ millions )'] == '2010']\n",
      "\n",
      "# Save the answer of the question in a variable\n",
      "answer = df_2010['total ( in $ millions )'].values[0]\n",
      "\n",
      "# Print the variable\n",
      "print(answer)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "13it [05:04, 22.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of csv is less than 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "14it [05:19, 20.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "     1    ,     -    ,     2008    ,     2007    ,     2006    ,\n",
      "     3    ,     fuel surcharges    ,     1.8    ,     .2    ,     1.1    ,\n",
      "     4    ,     environmental fees    ,     .4    ,     .2    ,     .4    ,\n",
      "     5    ,     recycling commodities    ,     .1    ,     .9    ,     -.1 ( .1 )    ,\n",
      "\n",
      "questions What is core price for 2006 ?\n",
      "ground truth 3.4% ( 3.4 % )\n",
      "predictions import pandas as pd\n",
      "\n",
      "# Read the csv file\n",
      "df = pd.read_csv('data.csv')\n",
      "\n",
      "# Get the core price for 2006\n",
      "core_price_2006 = df['2006']\n",
      "\n",
      "# Print the core price\n",
      "print(core_price_2006)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/llm/Large-Language-Model-for-Key-Value-Extractions/.venv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "15it [05:33, 22.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "     1    ,     -    ,     shares    ,     average grant datefair value per share    ,\n",
      "     2    ,     beginning of year    ,     4999    ,     $ 50.33    ,\n",
      "     3    ,     granted    ,     2295    ,     $ 63.79    ,\n",
      "     6    ,     end of year    ,     6898    ,     $ 54.69    ,\n",
      "\n",
      "questions What is the value for canceled ?\n",
      "ground truth ['-86 ( 86 )' '$ 56.53' '$ 999343' '$ 926512']\n",
      "predictions import pandas as pd\n",
      "\n",
      "df = pd.read_csv('data.csv')\n",
      "\n",
      "# Find the value for canceled\n",
      "canceled_value = df.loc[df['status'] == 'canceled', 'value'].values[0]\n",
      "\n",
      "print(canceled_value)\n",
      "***************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# with open(filename, 'w') as file:\n",
    "for i, row in tqdm(data[:15].iterrows()):\n",
    "    try: \n",
    "        soup = BeautifulSoup(row['html_content'], 'html.parser')\n",
    "\n",
    "        # Find the table\n",
    "        table = soup.find('table')\n",
    "        csv_data = save_rows(table)\n",
    "        csv_data = get_final_csv(csv_data)\n",
    "        ip = prompt_formatter_for_code(csv_data, row['question'])\n",
    "\n",
    "        output = llm(ip)[0]['generated_text']\n",
    "        print(i)\n",
    "        print(csv_data)\n",
    "        print('questions', row['question'])\n",
    "        print('ground truth', row['answer'])\n",
    "\n",
    "        pred = extract(output) \n",
    "        print('predictions', pred)\n",
    "        print('***************************************')\n",
    "    except:\n",
    "        print('length of csv is less than 3')\n",
    "    # output_df.at[i, 'csv'] = csv_data\n",
    "    # output_df.at[i, 'question'] = data.loc[i,'question']\n",
    "    # output_df.at[i, 'answer'] = data.loc[i,'answer']\n",
    "    # output_df.at[i, 'prediction'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('t1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14918"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "import os\n",
    " \n",
    "# Get the process ID of the current Jupyter Notebook server\n",
    "pid = os.getpid()\n",
    "pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
